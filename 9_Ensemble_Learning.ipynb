{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9_Ensemble_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMi8VBk22NtdkrJHeIJQLfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jellyho/AI_Learning_jellyho/blob/main/9_Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S57_t6Iw1icp"
      },
      "source": [
        "다수결 투표를 이용한 앙상블 학습\n",
        "\n",
        "다수결 투표 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBUsg2gNit7S"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.externals import six\n",
        "from sklearn.base import clone\n",
        "from sklearn.pipeline import _name_estimators\n",
        "import numpy as np\n",
        "import operator\n",
        "\n",
        "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, classifiers, vote='classlabel', weights=None):\n",
        "    self.classifiers = classifiers\n",
        "    self.named_classifiers = {key: value for key, value in _name_estimators(classifiers)}\n",
        "    self.vote = vote\n",
        "    self.weights = weights\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.labelenc_ = LabelEncoder()\n",
        "    self.labelenc_.fit(y)\n",
        "    self.classes_ = self.labelenc_.classes_\n",
        "    self.classifiers_ = []\n",
        "\n",
        "    for clf in self.classifiers:\n",
        "      fitted_clf = clone(clf).fit(X, self.labelenc_.transform(y))\n",
        "      self.classifiers_.append(fitted_clf)\n",
        "    \n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    if self.vote == 'probability':\n",
        "      maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
        "    \n",
        "    else:\n",
        "      predictions = np.asarray([clf.predict(X) for clf in self.classifiers_]).T\n",
        "      maj_vote = np.apply_along_axis(lambda x: np.argmax(np.bincount(x, weights=self.weights)), axis=1, arr=predictions)\n",
        "    \n",
        "    maj_vote = self.labelenc_.inverse_transform(maj_vote)\n",
        "    return maj_vote\n",
        "\n",
        "  def decision_function(self, X):\n",
        "    return self.predict(X)\n",
        "    \n",
        "  def predict_proba(self, X):\n",
        "    probas = np.asarray([clf.predict_proba(X) for clf in self.classifiers_])\n",
        "    avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "    if not deep:\n",
        "      return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
        "    else:\n",
        "      out = self.named_classifiers.copy()\n",
        "      for name, step in six.iteritems(self.named_classifiers):\n",
        "        for key, value in six.iteritems(step.get_params(deep=True)):\n",
        "          out['%s__%s' % (name, key)] = value\n",
        "      return out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph8ketgR1oVw"
      },
      "source": [
        "붗꽃 데이터로 각 분류기별 스코어 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWUAdTiet7GF",
        "outputId": "5c8bb2b2-de3d-4619-ae0e-9a1cd3d36e96"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data[50:, [1,2]], iris.target[50:]\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1, stratify=y)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "clf1 = LogisticRegression(solver='liblinear', penalty='l2', C=0.001, random_state=10)\n",
        "clf2 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=10)\n",
        "clf3 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
        "\n",
        "pipe1 = Pipeline([['sc', StandardScaler()], ['clf', clf1]])\n",
        "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
        "\n",
        "clf_labels = ['Logistic regression', 'Descision Tree', 'KNN']\n",
        "\n",
        "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
        "  scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10)\n",
        "  print(scores.mean(), scores.std(), label)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8400000000000001 0.19595917942265423 Logistic regression\n",
            "0.86 0.2009975124224178 Descision Tree\n",
            "0.8399999999999999 0.14966629547095767 KNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GslsO9FR1wBO"
      },
      "source": [
        "앙상블 분류기를 이용했을 때... 정확도가 높아진 것을 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Uvi4tTySdO",
        "outputId": "daed0282-e2e1-4521-e0bc-37fb63f70758"
      },
      "source": [
        "en_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])\n",
        "clf_labels = ['Logistic regression', 'Descision Tree', 'KNN', 'Majority voting']\n",
        "\n",
        "all_clf = [pipe1, clf2, pipe3, en_clf]\n",
        "for clf, label in zip(all_clf, clf_labels):\n",
        "  scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10)\n",
        "  print(scores.mean(), scores.std(), label)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8400000000000001 0.19595917942265423 Logistic regression\n",
            "0.86 0.2009975124224178 Descision Tree\n",
            "0.8399999999999999 0.14966629547095767 KNN\n",
            "0.8800000000000001 0.18330302779823357 Majority voting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OlCWLPD12LQ"
      },
      "source": [
        "매개변수 튜닝을 하기 위해 각 객체의 매개변수에 접근해야함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGsjxeiI18BL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}